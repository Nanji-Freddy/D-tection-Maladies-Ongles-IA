{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ex8yeoF0CQRx"
      },
      "outputs": [],
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YiC1NoqdCQRz"
      },
      "outputs": [],
      "source": [
        "# Define the paths for your dataset\n",
        "train_dir = \"data/train\"\n",
        "valid_dir = \"data/validation\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "Fz2cmrH8CQR0",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Tp_efrei\\Projet hackaton\\D-tection-Maladies-Ongles-IA\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import timm\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DGZcbC3fCQR0"
      },
      "outputs": [],
      "source": [
        "# Define the transformations for the train and validation data\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((192, 192)),\n",
        "    transforms.ColorJitter(brightness=0.125, contrast=0.125, saturation=0.05, hue=0.025),\n",
        "    transforms.RandomAffine(degrees=10, translate=(0.075, 0.075), shear=0.025),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "valid_transforms = transforms.Compose([\n",
        "    transforms.Resize((192, 192)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Load datasets using ImageFolder\n",
        "train_data = ImageFolder(root=train_dir, transform=train_transforms)\n",
        "valid_data = ImageFolder(root=valid_dir, transform=valid_transforms)\n",
        "\n",
        "# DataLoader for train and validation\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "valid_loader = DataLoader(valid_data, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5PB-SOjpCQR0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\Tp_efrei\\Projet hackaton\\D-tection-Maladies-Ongles-IA\\myenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\nanji\\.cache\\huggingface\\hub\\models--timm--resnet18d.ra2_in1k. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n"
          ]
        }
      ],
      "source": [
        "# Load the ResNet18 model from timm\n",
        "model = timm.create_model('resnet18d', pretrained=True, num_classes=len(train_data.classes))\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=3.25e-4, weight_decay=1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Rpc8W0PQCQR1"
      },
      "outputs": [],
      "source": [
        "# Training loop\n",
        "def train_model(model, train_loader, valid_loader, criterion, optimizer, epochs=16):\n",
        "    model.train()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        accuracy = 100 * correct / total\n",
        "        print(f'Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}, Accuracy: {accuracy}%')\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in valid_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_accuracy = 100 * val_correct / val_total\n",
        "        print(f'Validation Loss: {val_loss / len(valid_loader)}, Validation Accuracy: {val_accuracy}%')\n",
        "    torch.save(model.state_dict(), \"models/model.pth\")\n",
        "        \n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "DD3CFphMCQR1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.20940416968531078, Accuracy: 93.05555555555556%\n",
            "Validation Loss: 0.10299264639616013, Validation Accuracy: 96.7032967032967%\n",
            "Epoch 2, Loss: 0.37274056513849485, Accuracy: 86.48504273504274%\n",
            "Validation Loss: 0.30067891099800664, Validation Accuracy: 86.81318681318682%\n",
            "Epoch 3, Loss: 0.3205676314413038, Accuracy: 89.39636752136752%\n",
            "Validation Loss: 0.28633904705444974, Validation Accuracy: 92.3076923076923%\n",
            "Epoch 4, Loss: 0.17341858360311416, Accuracy: 94.04380341880342%\n",
            "Validation Loss: 0.11076579242944717, Validation Accuracy: 97.8021978021978%\n",
            "Epoch 5, Loss: 0.16086507593400967, Accuracy: 93.99038461538461%\n",
            "Validation Loss: 0.14334202061096826, Validation Accuracy: 93.4065934065934%\n",
            "Epoch 6, Loss: 0.15890930438191336, Accuracy: 94.33760683760684%\n",
            "Validation Loss: 0.23347988951718435, Validation Accuracy: 94.50549450549451%\n",
            "Epoch 7, Loss: 0.14267525693767855, Accuracy: 95.11217948717949%\n",
            "Validation Loss: 0.09789642800266544, Validation Accuracy: 95.6043956043956%\n",
            "Epoch 8, Loss: 0.10226715231537183, Accuracy: 96.39423076923077%\n",
            "Validation Loss: 0.0647433598836263, Validation Accuracy: 97.8021978021978%\n",
            "Epoch 9, Loss: 0.09853697671658462, Accuracy: 96.42094017094017%\n",
            "Validation Loss: 0.09482972091063857, Validation Accuracy: 94.50549450549451%\n",
            "Epoch 10, Loss: 0.09129767395500253, Accuracy: 97.03525641025641%\n",
            "Validation Loss: 0.09987059732278188, Validation Accuracy: 96.7032967032967%\n",
            "Epoch 11, Loss: 0.0934575054094068, Accuracy: 96.63461538461539%\n",
            "Validation Loss: 0.33300865814089775, Validation Accuracy: 91.20879120879121%\n",
            "Epoch 12, Loss: 0.08364452843347357, Accuracy: 97.24893162393163%\n",
            "Validation Loss: 0.08812719187699258, Validation Accuracy: 96.7032967032967%\n",
            "Epoch 13, Loss: 0.08269354361945237, Accuracy: 97.24893162393163%\n",
            "Validation Loss: 0.14811662087837854, Validation Accuracy: 93.4065934065934%\n",
            "Epoch 14, Loss: 0.0702111486158469, Accuracy: 97.27564102564102%\n",
            "Validation Loss: 0.246406356493632, Validation Accuracy: 92.3076923076923%\n",
            "Epoch 15, Loss: 0.06715576820031732, Accuracy: 97.54273504273505%\n",
            "Validation Loss: 0.5356697750006182, Validation Accuracy: 89.01098901098901%\n",
            "Epoch 16, Loss: 0.21498744012628737, Accuracy: 93.75%\n",
            "Validation Loss: 0.14307870840032896, Validation Accuracy: 95.6043956043956%\n"
          ]
        }
      ],
      "source": [
        "# Run training\n",
        "train_model(model, train_loader, valid_loader, criterion, optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "🤖Nail Disease Detection🤖",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 5625424,
          "sourceId": 9292141,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30775,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
